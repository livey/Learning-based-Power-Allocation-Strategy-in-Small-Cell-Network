{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import sys\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from numpy.random import choice\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter, sub\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, explained_variance_score, mean_squared_error, mean_absolute_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class tempDebugging:\n",
    "    'temporary functions for debugging and detecting the system, which will not be inlcuded in main function'\n",
    "    @staticmethod\n",
    "    def doubleLinkPercentage(df):\n",
    "        'return the number of links that is doulbe direction'\n",
    "        linkNum = 0\n",
    "        doubleDirectNum = 0\n",
    "        for curCell in df.index:\n",
    "            nbList = df.loc[curCell,'Cluster'] + [] # to make it a copy instead of work on the same list\n",
    "            linkNum += len(nbList)\n",
    "            for nb in nbList:\n",
    "                if curCell in df.loc[nb,'Cluster']:\n",
    "                    doubleDirectNum += 1\n",
    "        print(linkNum)\n",
    "        print(doubleDirectNum)\n",
    "        print((doubleDirectNum+0.0)/linkNum)\n",
    "        return linkNum, doubleDirectNum\n",
    "\n",
    "#tempDebugging.doubleLinkPercentage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InitData:\n",
    "    'functions to deal with input'\n",
    "    @staticmethod\n",
    "    def genInput(filename):\n",
    "        'generate DataFrame input from .csv file'\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data.loc[:,['Iteration Num','CellId','PilotPower','Load','TBS(kbit)','Users',\\\n",
    "                          'Cluster','DeltaLoad']]\n",
    "        tempIterationNum = data['Iteration Num'].iloc[0]\n",
    "        data =data[data['Iteration Num'] == tempIterationNum ]\n",
    "        return data    \n",
    "    \n",
    "    @staticmethod\n",
    "    def init(originDf):\n",
    "        'convert Cluster and DeltaLoad to list'\n",
    "        rowNum = len(originDf)\n",
    "        newCluster =[]\n",
    "        for rowIter in range(0,rowNum):\n",
    "            nb = originDf.iloc[rowIter]['Cluster']\n",
    "            nb = nb.split(';')\n",
    "            nb = nb[0:-1]\n",
    "            nb =[int(j) for j in nb]\n",
    "            newCluster.append(nb)  \n",
    "        newCluster = pd.Series(newCluster,originDf.index)\n",
    "        originDf['Cluster'] = newCluster\n",
    "        #processing DeltaLoad\n",
    "        rowNum = len(originDf)\n",
    "        newCluster =[]\n",
    "        for rowIter in range(0,rowNum):\n",
    "            nb = originDf.iloc[rowIter]['DeltaLoad']\n",
    "            nb = nb.split(';')\n",
    "            nb = nb[0:-1]\n",
    "            nb =[float(j) for j in nb]\n",
    "            newCluster.append(nb)  \n",
    "        newCluster = pd.Series(newCluster,originDf.index)\n",
    "        originDf['DeltaLoad'] = newCluster\n",
    "        return\n",
    "    \n",
    "    @staticmethod\n",
    "    def getFeatureIndex(df):\n",
    "        'to add the AverageLoad feature, AffectCluster feature and set cellID as index'\n",
    "        # averageLoad feature\n",
    "        rowNum = len(df)\n",
    "        newFeature = []\n",
    "        for rowIter in range(0,rowNum):\n",
    "            averageLoad = np.mean(df.iloc[rowIter]['DeltaLoad'])\n",
    "            averageLoad = averageLoad*5.0/6.0\n",
    "            averageLoad = df.iloc[rowIter]['Load'] - averageLoad\n",
    "            newFeature.append(averageLoad)\n",
    "        newFeature = pd.Series(newFeature,df.index)\n",
    "        df['averageLoad'] = newFeature\n",
    "        # set new index now\n",
    "        df.set_index('CellId',inplace = True)\n",
    "        # AffectCluster feature\n",
    "        rowNum = len(df)\n",
    "        AffectCluster =[set() for x in range(rowNum)]\n",
    "        AffectCluster = pd.Series(AffectCluster, df.index)\n",
    "        df['affectCluster'] = AffectCluster\n",
    "        for startCell in df.index:\n",
    "            for endCell in df.loc[startCell,'Cluster']:\n",
    "                df.loc[endCell,'affectCluster'].add(startCell)        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    'configure the parameters of the system'\n",
    "    def __init__(self):\n",
    "        self.optIterNum = 20\n",
    "        self.actDomain = list(np.linspace(30,36,num = 7))\n",
    "        self.T = 0.5\n",
    "        self.result_TtooSmall = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainingNNModel:\n",
    "    'to train neural network for the features'\n",
    "    def __init__(self):\n",
    "        self.model = MLPRegressor() # neural network model\n",
    "        self.scaler = StandardScaler() # scaler of input\n",
    "        \n",
    "    def train(self,feature,target):\n",
    "        self.scaler.fit(feature)\n",
    "        self.model.fit(self.scaler.transform(feature),target)\n",
    "        print(self.model.score(self.scaler.transform(feature),target))\n",
    "        \n",
    "    def predict(self,feature):\n",
    "        return self.model.predict(self.scaler.transform(feature))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ProcessFuns:\n",
    "    'functions in processing'    \n",
    "    @staticmethod\n",
    "    def getFeature(tempCell, df, changeCell=-1, action=-1):\n",
    "        'feature as [Pilot power, neighbor pilot power *5, averageLoad]'\n",
    "        feature = []\n",
    "        # deal with the case without changeCell\n",
    "        if changeCell == -1:\n",
    "            changeCell = tempCell\n",
    "            action = df.loc[tempCell,'PilotPower']         \n",
    "        # now process\n",
    "        if tempCell != changeCell:\n",
    "            feature.append(df.loc[tempCell,'PilotPower'])\n",
    "        else:\n",
    "            feature.append(action)\n",
    "        for nb in df.loc[tempCell,'Cluster']:\n",
    "            if nb != changeCell:\n",
    "                feature.append(df.loc[nb,'PilotPower'])\n",
    "            else:\n",
    "                feature.append(action)\n",
    "        while len(feature)<6:\n",
    "            feature.append(29.5) # to be revised\n",
    "        feature.append(df.loc[tempCell,'averageLoad'])\n",
    "        return feature\n",
    "    \n",
    "    @staticmethod\n",
    "    def probGen(nnModel,changeCell,df,config):\n",
    "        cellList = [changeCell] + list(df.loc[changeCell, 'affectCluster'])\n",
    "        probWeight = []\n",
    "        for act in config.actDomain:\n",
    "            value = []\n",
    "            for tempCell in cellList:\n",
    "                tempFeature = ProcessFuns.getFeature(tempCell,df,changeCell,act)\n",
    "                value.append(nnModel.predict([tempFeature])[0])\n",
    "            probWeight.append(sum(value))\n",
    "        if config.T == 0:\n",
    "            prob = [0.0] * len(probWeight)\n",
    "            maxInd = probWeight.index(max(probWeight))\n",
    "            prob[maxInd] = 1.0\n",
    "        elif max(probWeight)/config.T >= math.log(sys.float_info.max):\n",
    "            config.result_TtooSmall  = 1\n",
    "            prob = [0.0] * len(probWeight)\n",
    "            maxInd = probWeight.index(max(probWeight))\n",
    "            prob[maxInd] = 1.0\n",
    "        else:\n",
    "            probWeight = [math.exp(x/config.T) for x in probWeight]\n",
    "            prob = [x/sum(probWeight) for x in probWeight]\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 's.csv'\n",
    "# initialize data\n",
    "myInput = InitData.genInput(filename)# to change input here\n",
    "df = myInput.copy() \n",
    "InitData.init(df)\n",
    "InitData.getFeatureIndex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# config settings\n",
    "config = Config()\n",
    "config.optIterNum = 20\n",
    "config.actDomain = list(np.linspace(30,36,num = 13)) # num = 7 or 13\n",
    "config.T = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34978.821132349891, 36783.626968747369, 37079.335864770721, 37164.503721260022, 37178.792162100421, 37197.967324014258, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606, 37199.449222374606]\n"
     ]
    }
   ],
   "source": [
    "# --------now, proceed to proceeding ----------------\n",
    "nnModel = pickle.load(open('s.csv.pkl','rb'))\n",
    "utility = []\n",
    "for curIter in range(0,config.optIterNum):\n",
    "    curUtility = 0\n",
    "    for curCell in df.index:\n",
    "        tempFeature = ProcessFuns.getFeature(curCell,df)\n",
    "        curUtility += nnModel.predict([tempFeature])[0]\n",
    "    utility.append(curUtility)\n",
    "    for curCell in df.index:\n",
    "        prob = ProcessFuns.probGen(nnModel, curCell, df, config)\n",
    "        curAct = choice(config.actDomain, 1, p=prob)\n",
    "        df.loc[curCell,'PilotPower'] = curAct   \n",
    "print(utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myOutput = df['PilotPower'].copy()\n",
    "#myOutput is the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.3063;-0.305;0.1875;-0.306;0.2616;'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myInput.head(3)\n",
    "myInput.loc[0,'DeltaLoad']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
