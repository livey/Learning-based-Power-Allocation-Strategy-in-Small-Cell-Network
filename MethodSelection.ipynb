{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn import preprocessing,cross_validation,tree,metrics,decomposition,linear_model,pipeline,svm,grid_search,learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.interpolate import spline\n",
    "import xlrd\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from numpy.random import choice\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter, sub\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, explained_variance_score, \\\n",
    "    mean_squared_error, mean_absolute_error, median_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.mlab as mlab   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "def linear_regressor():\n",
    "    linear_regression = linear_model.LinearRegression()\n",
    "    return linear_regression\n",
    "\n",
    "# LASSO regression\n",
    "def lasso_regressor():\n",
    "    lasso_params = {'alpha':[0.001,0.1,1.0,10.0,100.0]}\n",
    "    grid_lasso = grid_search.GridSearchCV(linear_model.Lasso(),lasso_params)\n",
    "    return grid_lasso\n",
    "    \n",
    "# SVM regressor\n",
    "def svr():\n",
    "    svm_params = {'C':[1.0,10.0,100.0],'epsilon':[0.01,0.1,1.0],'kernel':['linear','poly','rbf','sigmoid'],\n",
    "                  'degree':[2,3,5],'gamma':[0.001,0.01,0.1],'coef0':[0.0,1.0]}\n",
    "    grid_svm = grid_search.GridSearchCV(svm.SVR(),svm_params)\n",
    "    return svm.SVR(C=1000)\n",
    "\n",
    "# Decision tree regressor\n",
    "def dtree():\n",
    "    tree_params = {'max_depth':[50,100],'min_samples_leaf':[2,3,5,10]}\n",
    "    grid_tree = grid_search.GridSearchCV(sklearn.tree.DecisionTreeRegressor(),tree_params)\n",
    "    return grid_tree\n",
    "\n",
    "# Baysian Ridge Regressor\n",
    "def bayseian():\n",
    "    bayseian_params = {'n_iter':[300,500],'alpha_1':[1e-5,1e-6],'alpha_2':[1e-5,1e-6],'lambda_1':[1e-5,1e-6],\n",
    "                      'lambda_2':[1e-5,1e-6]}\n",
    "    grid_bay = grid_search.GridSearchCV(linear_model.BayesianRidge(),bayseian_params)\n",
    "    return grid_bay\n",
    "    \n",
    "# Logistic Regressor\n",
    "def logistic():\n",
    "    log_params = {'penalty':['l1','l2'],'C':[1.0,10.0,100.0]}\n",
    "    grid_log = grid_search.GridSearchCV(linear_model.LogisticRegression(),log_params)\n",
    "    return grid_log\n",
    "\n",
    "# Plot the performance of regressors\n",
    "# Input: key = 1 is the R^2 score, key = 2 is the MSE\n",
    "\n",
    "def neuralnet():\n",
    "    neural_params = {'hidden_layer_sizes':[10,20,50],'activation':['logistic'],'alpha':[0.0001],'max_iter':[2000,20000]}\n",
    "    grid_neural = grid_search.GridSearchCV(MLPRegressor(),neural_params)\n",
    "    return grid_neural\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileToSamples:\n",
    "    'convert the input .csv file to samples(Dataframe):\\\n",
    "    [Iteration,CellId,PilotPower,Load,Users,TBS,NB1Id*5,NB1Power*5,NB1Users*5,NB1Load*5\\\n",
    "    AveragePower,AverageLoad,AverageUser,TimeAveragePower,TimeAverageLoad,TimeAverageUser] '\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        self.samples = pd.read_pickle(filename) # type DataFrame (pandas package)  \n",
    "        # use for test feature selection\n",
    "        self.feature = FileToSamples.__getFeatues(self.samples)  # type DataFrame (pandas package) \n",
    "        self.target=self.samples['TBS']\n",
    "    @staticmethod\n",
    "    def __getFeatues(samples):\n",
    "        Testnumber =1\n",
    "        feature=[]\n",
    "        #nnEstimater = [TrainingNNModel()]*Testnumber\n",
    "        feature=[pd.DataFrame()]*Testnumber\n",
    "        feature[0]= samples[['PilotPower','TimeAverageLoad','TimeAverageUsers','NB1Power','NB2Power','NB3Power','NB4Power','NB5Power']] \n",
    "        return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(regressor):\n",
    "    \n",
    "    trainingFile = 'Data__Random3.csv.pkl'\n",
    "    #trainingFile = 'Workbook2.csv'\n",
    "    testFile = 'Data__Random4.csv.pkl'\n",
    "    \n",
    "    testData = FileToSamples(testFile)\n",
    "    trainData = FileToSamples(trainingFile)\n",
    "    scaler = StandardScaler()  \n",
    "    \n",
    "    X_train= trainData.feature[0]\n",
    "    X_test= testData.feature[0]\n",
    "    y_train=trainData.target\n",
    "    y_test=testData.target\n",
    "        \n",
    "    model = regressor.fit(X_train,y_train)\n",
    "    score = model.score(X_test,y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = metrics.mean_squared_error(y_test,y_pred) # Mean squared error        \n",
    "    return model, score, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result=6*[None]\n",
    "score=6*[None]\n",
    "mse=6*[None]\n",
    "regressor=[linear_regressor(),lasso_regressor(),svr(),dtree(),bayseian(),neuralnet()]\n",
    "\n",
    "for i in range(6):\n",
    "    result[i],score[i],mse[i]=get_score(regressor[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5102492736727265,\n",
       " 0.5102565163897443,\n",
       " 0.6079625569440468,\n",
       " 0.4146100607945446,\n",
       " 0.5102844485744826,\n",
       " 0.8241619106480704]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8393.825569339597,\n",
       " 8393.701436592002,\n",
       " 6719.120027323015,\n",
       " 10032.98367025468,\n",
       " 8393.222707569543,\n",
       " 3013.6846585904755]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
